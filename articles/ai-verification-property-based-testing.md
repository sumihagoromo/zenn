---
title: "AIの出力、信じちゃダメ！🔍 プロパティベースドテストに学ぶ「検証」のススメ"
emoji: "✨"
type: "idea"
topics: ["AI", "テスト", "プロパティベースドテスト", "LLM", "開発手法"]
published: true
---

## AIって「賢いお友達」じゃないよ？

「AIに聞けば正解が返ってくる〜！」

……って思ってない？ ちょっと待って！

AIってね、中身が見えないの。**ブラックボックス**なの。なんでその答えが出てきたのか、実は誰にもわからないんだよ？

これってどこかで聞いたことない？

そう、**テストしたいコード**と同じ！

## 「答えを覚える」テスト vs 「性質を検証する」テスト

普通のテストってこう書くよね：

```scala
test("add(2, 3) は 5 になるはず") {
  assert(add(2, 3) == 5)
}
```

これって「入力Aなら出力B！」って**答えを覚えてる**の。

でもね、プロパティベースドテスト（ScalaCheckとかQuickCheckとか）は違うの：

```scala
property("足し算は順番入れ替えても同じ！") {
  forAll { (a: Int, b: Int) =>
    add(a, b) == add(b, a)
  }
}

property("0を足しても変わらない！") {
  forAll { (x: Int) =>
    add(x, 0) == x
  }
}
```

具体的な答えは知らないの。**「これは絶対満たすべきでしょ！」っていう性質**だけ決めて、いろんな入力でチェックし続けるの。

## AIもブラックボックス関数だよ！

AIにプロンプト投げるのって、関数呼び出しと一緒：

```
output = AI(prompt, context)
```

中身見えないでしょ？ **見えないものを信じちゃダメ**なの！

じゃあどうするか？

**出力が「期待する性質」を持ってるかだけ検証する！**

## AI活用、プロパティベースドでいこ！

### 1.「正解」じゃなくて「性質」を決めよう

❌ ダメな例：
> 「このコードのバグ直して〜」→ 返ってきたコードそのまま使っちゃう

✅ いい例：
> 「このコードのバグ直して〜」→ 返ってきたコードをチェック！
> - コンパイル通る？
> - 既存のテスト壊れてない？
> - 問題の入力でちゃんと動く？
> - 他のところ変になってない？

### 2. 検証できる「性質」ってこんな感じ

**コード生成なら：**
- 構文エラーない？（パースできる？）
- 型おかしくない？
- 欲しい関数ちゃんとある？
- 既存テスト通る？

**文章生成なら：**
- 文字数オーバーしてない？
- 必要なキーワード入ってる？
- NGワード混ざってない？
- JSON/Markdownとしてちゃんと読める？

**データ変換なら：**
- 件数合ってる？
- 大事なデータ消えてない？
- 元に戻せる？（必要なとき）

### 3. 検証、自動化しちゃお！

```python
def verify_code_output(generated_code: str) -> bool:
    """AIが生成したコードの性質をチェック！"""

    # 性質1: 構文エラーない？
    try:
        ast.parse(generated_code)
    except SyntaxError:
        return False

    # 性質2: 危ないimportない？
    if re.search(r'import\s+(os|subprocess|eval)', generated_code):
        return False

    # 性質3: 欲しい関数ある？
    if 'def process_data(' not in generated_code:
        return False

    return True

# ダメだったらもう一回！
for attempt in range(max_retries):
    output = call_ai(prompt)
    if verify_code_output(output):
        break  # やったー！
```

### 4. 何がダメだったか教えてあげよう

検証失敗したら、**どこがダメだったかAIに伝えて**もう一回：

```python
if not verify_result.syntax_valid:
    prompt += f"\n\nさっきの構文エラーだったよ💦: {error_message}\n直してね！"
```

プロパティベースドテストで反例見つかったらコード直すのと一緒！

## このやり方、なんでいいの？

### 「信頼」じゃなくて「検証」で回す！

AIを「信頼できる先生」って思ってると、裏切られたとき困っちゃう。

AIを「検証できる出力を出す関数」って思えば、信頼なんていらないの。必要なのは**明確な性質と検証ロジック**だけ！

### AIの得意・不得意とピッタリ合う

AIはね、「この性質を満たす出力出して！」は得意なの。制約があれば、その中でいい感じに作ってくれる。

でもね、「そもそもこの性質でいいんだっけ？」って疑うのは苦手。**それは人間のお仕事**！

つまりね：
- **人間**：何をチェックするか決める（性質を決める）
- **AI**：その性質を満たす出力を作る
- **人間**：ちゃんと満たしてるか検証する

この役割分担、すっごく自然でしょ？

## 答えを覚えるな、検証せよ！

科学の本質ってね、知識をいっぱい覚えることじゃないの。**検証し続けること**なの。

「AIがこう言ってた」を覚えても意味ないよ？ AIの出力を検証し続けることにこそ価値があるの！

「絶対の真理」を信じるんじゃなくて、検証できる性質を決めて、何度も何度もチェックする。プロパティベースドテストが教えてくれるのは、こういう世界との向き合い方なんだ。

AIっていう強力なブラックボックスを手に入れた今だからこそ、この考え方が大事になってくるよ！

---

*「信じるな、検証せよ」—— AI時代を生きるわたしたちの合言葉、そして科学の原点✨*
